{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\edgarmp\\AppData\\Local\\Temp\\ipykernel_22944\\1378044173.py:10: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import sys\n",
    "from pprint import pprint\n",
    "from dotenv import load_dotenv\n",
    "import pathlib\n",
    "# from tqdm import tqdm\n",
    "from tqdm.autonotebook import tqdm\n",
    "from pathlib import Path\n",
    "from pprint import pprint\n",
    "import hashlib\n",
    "\n",
    "import polars as pl\n",
    "from glob import glob\n",
    "\n",
    "from openai import OpenAI\n",
    "from pinecone import Pinecone\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "from google import genai\n",
    "from google.genai import types\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "import PIL.Image\n",
    "import pymupdf\n",
    "\n",
    "\n",
    "root_dir = Path(os.getcwd()).parent.parent\n",
    "sys.path.insert(0, str(root_dir))\n",
    "\n",
    "pl.Config.set_fmt_str_lengths(300)\n",
    "pl.Config.set_tbl_rows(100)\n",
    "pl.Config.set_tbl_cols(20);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.d01_data.data import (read_json, json_dump, pdf_to_images, save_text_to_file, get_orientacion_docs)\n",
    "from src.d03_modeling.pydantic_schemas import DocumentoInfo, Instrucciones, Formulario, SiNo\n",
    "from src.d03_modeling.prompts import EXTRACT_FORM_TYPE, EXTRACT_FORM_INSTRUCTIONS, EXTRACT_FORM_MAIN_SECTIONS, is_doc_present_in_text_message\n",
    "from src.d00_utils.utils import split_pdf_into_pages, remove_duplicates, campos_to_srt\n",
    "from src.d03_modeling.modeling import get_imputation_campos, get_imputation_seleccion, create_resumen\n",
    "\n",
    "\n",
    "load_dotenv('../../.env')\n",
    " \n",
    "raw_path = root_dir / 'data' / '01_raw'\n",
    "intermediate_path = root_dir / 'data' / '02_intermediate'\n",
    "clean_path = root_dir / 'data' / '03_clean'\n",
    "output_path = root_dir / 'data' / '04_model_output'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')\n",
    "OPENAI_MODEL = os.getenv('OPENAI_MODEL')\n",
    "GEMINI_API_KEY = os.getenv('GEMINI_API_KEY')\n",
    "GEMINI_MODEL = os.getenv('GEMINI_MODEL')\n",
    "\n",
    "client = genai.Client(api_key=GEMINI_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File saved in c:\\Users\\edgarmp\\Desktop\\Proyectos\\ODIASEIA hackaton\\data\\02_intermediate\\formularios\\español\\EX-10\\EX-10_0.pdf\n",
      "File saved in c:\\Users\\edgarmp\\Desktop\\Proyectos\\ODIASEIA hackaton\\data\\02_intermediate\\formularios\\español\\EX-10\\EX-10_1.pdf\n",
      "File saved in c:\\Users\\edgarmp\\Desktop\\Proyectos\\ODIASEIA hackaton\\data\\02_intermediate\\formularios\\español\\EX-10\\EX-10_2.pdf\n",
      "File saved in c:\\Users\\edgarmp\\Desktop\\Proyectos\\ODIASEIA hackaton\\data\\02_intermediate\\formularios\\español\\EX-17\\EX-17_0.pdf\n",
      "File saved in c:\\Users\\edgarmp\\Desktop\\Proyectos\\ODIASEIA hackaton\\data\\02_intermediate\\formularios\\español\\EX-17\\EX-17_1.pdf\n",
      "File saved in c:\\Users\\edgarmp\\Desktop\\Proyectos\\ODIASEIA hackaton\\data\\02_intermediate\\formularios\\español\\EX-17\\EX-17_2.pdf\n"
     ]
    }
   ],
   "source": [
    "formulario_files = sorted(glob(str(raw_path / 'formularios' / '*.pdf')))\n",
    "for formulario_file in formulario_files:\n",
    "    split_pdf_into_pages(formulario_file, output_path=intermediate_path / 'formularios' / 'español')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "formularios = sorted(glob(str(intermediate_path / 'formularios' / 'español' / '*/')))\n",
    "\n",
    "orientacion_files = glob(str(intermediate_path / 'orientacion' / '*.json'))\n",
    "processes = {Path(orientacion_file).stem:get_orientacion_docs(orientacion_file) for orientacion_file in orientacion_files}\n",
    "processes_with_text = {d:v for d,v in processes.items() if v[0]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2 [01:21<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "for formulario in tqdm(formularios):\n",
    "    pdfs = sorted(glob(str(Path(formulario) / '*.pdf')))\n",
    "    pdfs = [Path(pdf).read_bytes() for pdf in pdfs]\n",
    "    \n",
    "    \n",
    "    config = types.GenerateContentConfig(\n",
    "                system_instruction='Eres un analista de documentos sobre la inmigración española',\n",
    "                max_output_tokens=100,\n",
    "                top_p= 0.6,\n",
    "                temperature= 0.5,\n",
    "                response_mime_type= 'application/json',\n",
    "                response_schema=DocumentoInfo,\n",
    "            )\n",
    "    \n",
    "    doc_info = client.models.generate_content(\n",
    "                model=GEMINI_MODEL,\n",
    "                contents=[\n",
    "                    types.Part.from_bytes(\n",
    "                        data=pdfs[0],\n",
    "                        mime_type='application/pdf'),\n",
    "                    EXTRACT_FORM_TYPE],\n",
    "                config=config)\n",
    "\n",
    "\n",
    "    doc_code = doc_info.parsed.codigo_documento\n",
    "    doc_laws = '\\n'.join([ley.ley for ley in doc_info.parsed.leyes])\n",
    "    doc_laws = f'Leyes en las que sustentan:\\n{doc_laws}'\n",
    "    \n",
    "    \n",
    "    config.response_schema = Instrucciones\n",
    "    config.max_output_tokens = 800\n",
    "\n",
    "    doc_instructions = client.models.generate_content(\n",
    "                            model=GEMINI_MODEL,\n",
    "                contents=[\n",
    "                    types.Part.from_bytes(\n",
    "                        data=pdfs[-1],\n",
    "                        mime_type='application/pdf'),\n",
    "                    EXTRACT_FORM_INSTRUCTIONS],\n",
    "                config=config)\n",
    "\n",
    "    doc_instructions = '\\n'.join([f'{ins.numero}) {ins.instruccion}' for ins in doc_instructions.parsed.Instrucciones])\n",
    "    doc_instructions = f'Instrucciones de como rellenar el documento:\\n{doc_instructions}'\n",
    "\n",
    "    \n",
    "    config.response_schema = Formulario\n",
    "    config.max_output_tokens = 1_200\n",
    "\n",
    "    secciones_str = 'Secciones a rellenar del formulario:'\n",
    "\n",
    "    all_campos_a_imputar = {}\n",
    "    all_campos_a_seleccionar = {}\n",
    "\n",
    "    for i, pdf in enumerate(pdfs[:-1]):\n",
    "        \n",
    "        doc_sections = client.models.generate_content(\n",
    "            model=GEMINI_MODEL,\n",
    "                contents=[\n",
    "                    types.Part.from_bytes(\n",
    "                        data=pdf,\n",
    "                        mime_type='application/pdf'),\n",
    "                    EXTRACT_FORM_MAIN_SECTIONS],\n",
    "                config=config)\n",
    "\n",
    "        \n",
    "        if doc_sections.parsed is not None:\n",
    "            page_sections = '\\n\\n'.join([f'Sección {sec.numero}) {sec.nombre}.\\nExplicacion: {sec.informacion}' for sec in doc_sections.parsed.secciones])\n",
    "            secciones_str = f'{secciones_str}\\n\\n{page_sections}'\n",
    "            \n",
    "        campos_a_imputar = get_imputation_campos(client=client, model=GEMINI_MODEL, pdf=pdf)\n",
    "        campos_a_imputar = remove_duplicates(campos_a_imputar.parsed.campos)\n",
    "        \n",
    "        campos_a_seleccionar = get_imputation_seleccion(client=client, model=GEMINI_MODEL, pdf=pdf)\n",
    "        campos_a_seleccionar = remove_duplicates(campos_a_seleccionar.parsed.campos)\n",
    "        \n",
    "        all_campos_a_imputar[i] = campos_a_imputar\n",
    "        all_campos_a_seleccionar[i] = campos_a_seleccionar\n",
    "    \n",
    "    campos_a_imputar = campos_to_srt(campos_obj=all_campos_a_imputar, imputados=True)\n",
    "    campos_a_seleccionar = campos_to_srt(campos_obj=all_campos_a_seleccionar, imputados=False)\n",
    "    \n",
    "    campos_str = f'Campos a rellenar:\\n\\n{campos_a_imputar}\\n{campos_a_seleccionar}'\n",
    "            \n",
    "    messages = is_doc_present_in_text_message([(doc_code, text[1]) for _, text in processes_with_text.items()])\n",
    "    llm = ChatOpenAI(\n",
    "        model=OPENAI_MODEL,\n",
    "        temperature=0.4,\n",
    "        max_tokens=10,\n",
    "        top_p=0.6,\n",
    "        timeout=None,\n",
    "        max_retries=2\n",
    "    ).with_structured_output(SiNo, include_raw=False, method ='json_schema', strict=True)\n",
    "\n",
    "    question_results = llm.batch(messages)\n",
    "    question_results = [True if res.resultado == 'si' else False for res in question_results]\n",
    "\n",
    "    final_processes = []\n",
    "    for (_, process), isin in zip(processes_with_text.items(), question_results):\n",
    "        if isin:\n",
    "            final_processes.append(process[0].strip())\n",
    "        \n",
    "    final_processes = '\\n'.join(final_processes)\n",
    "    final_processes = f'Procesos donde este formulario es necesario:\\n{final_processes}'\n",
    "    \n",
    "    final_doc_text = '\\n\\n'.join([f'Código del documento: {doc_code}', doc_laws, final_processes, doc_instructions, secciones_str])\n",
    "    resumen = create_resumen(client=client, model=GEMINI_MODEL, resumen=final_doc_text)\n",
    "    resumen = resumen.parsed.resumen\n",
    "    \n",
    "    final_doc_text = f'Resumen del documento:\\n{resumen}\\n\\n{final_doc_text}\\n\\n{campos_str}'\n",
    "    output_path = str((clean_path / 'formularios' / Path(formulario).stem)) + '.txt'\n",
    "    save_text_to_file(final_doc_text, output_path)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hackaton",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
